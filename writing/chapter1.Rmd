# Introduction

## Deep Learning

This thesis is about using *Deep Learning* (DL) approaches to solve *Machine Learning* (ML) tasks with tabular data inputs.
The field of DL is an extention of the class of ML algorithms called *Artifical Neural Networks* (NNs).
The rapid development in computing power and the growing abundance of data available, awoken the slumbering field of NNs and resulted in optimisation and architecture design advancements, creating the DL field as we know it today [@Lecun2015].

DL is receiving a remarkable amount of attention in academia and elsewhere (see \autoref{fig:dlpapers}).
DL has already shown tremendous value in application areas such as *Computer Vision* (CV) [@Hu2017], audio processing [@Battenberg2017], and *Natural Language Processing* (NLP) [@Devlin2018], significantly improving on the then *State of the Art* (SotA).
In the aformentioned application areas, DL reached a maturity level sufficient to be able to run these systems in a production/commercial environment, *e.g.* voice assistants [@Sarikaya2017] like Amazon Alexa, face recognition[^faceid] with Apple iPhones and language translation [@Wu2016] with Google to name a few.

[^faceid]: https://www.apple.com/business/site/docs/FaceID_Security_Guide.pdf

![The exponential growth of published papers and Google search terms containing the term *Deep Learning*\label{fig:dlpapers}. Sources: Google Trends[^googletrend], Semantic Scholar[^semschol]](figures/trends.pdf)

[^jeffdeantalk]: https://www.slideshare.net/AIFrontiers/jeff-dean-trends-and-developments-in-deep-learning-research
[^googletrend]: https://trends.google.com/trends/explore?date=all&q=deep%20learning
[^semschol]: https://www.semanticscholar.org/search?year%5B0%5D=2000&year%5B1%5D=2019&q=%22deep%20learning%22&sort=relevance

One of the most attractive attributes of DL is its ability to model almost any input-output relationship.
DL has been used to generate art [@Gatys2015] and music [@Mogren2016], controlling various modules in autonomous cars [@Fridman2017], playing video games [@Mnih2013], beating the world's best Go player [@Silver2017], suggesting which videos to watch [@Covington2016], and improving the quality of images [@Shi2016].

One thing that these sucessful DL applications have in common is that the modality of the data on which they operate is homegeneous.
In CV the data are pixel values, in NLP the data are words and in audio processing the data are sound waves.
This is not a criteria for DL to be sucessful but is certainly a driver for its sucess in these domains.
Modelling of homogeneous data is easier since every input feature can be treated the same.
Furthermore, universal patterns exist in each of these domains allowing for knowledge to be transferred between tasks of the same domain, both knowledge aquired by humans and that learned by the DL model.
For example in CV, advancements in classifying pictures of pets will most likely also be applicable to identifying tumuors in X-rays and the patterns learned by the model to do the one task may also be useful to do the other (see *Transfer Learning*).

A data domain in which DL does not flourish is that of tabular data.
Although work is being done on the problem [@Shavitt2018, @Song2018] and SotA results were received on rare occasions [@Brebisson2015] (and this competition[^port]), the area is nowhere near as mature or receiving as much attention compared to CV and NLP.
ML tasks operating on tabular data are typically more effectively solved by using tree-based methods as found by a large study done in [@Delgado2014],  and also evident by looking at the winning solutions of relevant Kaggle competitions[^kaggle].
This is possibly largely influenced by the heterogeneity of tabular data [@Shavitt2018], which forms part of the discussion in the next section.

[^kaggle]: https://www.kaggle.com
[^port]: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/discussion/44629

## Tabular Data

We call data that can be represented by a 2-dimensional table, where each of the rows of the table corresponds to one observation and each column denotes an individual meaningful feature, a *tabular dataset*.
See \autoref{tab:adult} for an extract of the Adult[^adult1] dataset, an example of a tabular dataset.

[^adult1]: http://archive.ics.uci.edu/ml/datasets/Adult

```{r, results='asis'}
df = read_csv('../data/adult/adult_sample.csv')
xtable(df, caption = 'Preview of the Adult dataset.\\label{tab:adult}')
```

\autoref{tab:adult} is a typical tabular dataset where the features (columns) are of mixed type, continuous and discrete/categorical, and containing various information.
The rows and columns are of no particular order.
The data comes from a US census and the specific task was to predict whether or not an indivdual earns more than $50,000 a year.

There are many important ML applications using tabular data:

- Various tasks on Electronic Health Records (EHR) like predicting in-hopsital mortality and prolonged length of stay [@Rajkomar2018].
- Recommender systems for items like videos [@Covington2016] or property listings [@haldar2018].
- Click-through rate (CTR) prediction for predicting which item a user will click on next [@Song2018]. 
- Predicting which clients are at risk of defaulting on their accounts[^loandef].
- Predicting store sales [@Guo2016].
- Drug discovery [@Klambauer2017].

[^loandef]: https://www.kaggle.com/c/loan-default-prediction

Tabular datasets come in all shapes and sizes.
The number of rows can range from hundreds to millions and the number of columns also has no limits.
It is not unusual for tabular datasets to be noisy.
A proportion of the observations may have missing features and/or incorrect values.
The continuous can be on vastly different scales, some containing outliers, and the categorical features can have high cardinality and lead to sparsity.

The most important part of building models for tabular datasets and the part that can result in the largest performance gains is the processing and manipulation of the input features [@Rajkomar2018].
This includes preprocessing, merging, customising, filtering and cleaning of the data.
In a process called feature engineering one strives to create new features from the original features based on some domain knowledge of the data or otherwise, that makes it easier for the model to learn from interactions betwen features and estimate the target.
This is a extremely laborious task with no clear recipe to follow and usually requires domain expertise to implement sucessfully.

Ensemble tree-based methods are currently the most effective ML models on tabular datasets.
One reason for that may be its robustness to feature scales and types and being able to effectively model interactions between various types of features with its hierachical feature splits and ensembling techniques.

The classical NN approaches applied to tabular data is no match for tree ensembles.
DL has advanced and matured a lot in recent years but it is not yet clear how to leverage these modern techniques to effectively build and train deep NNs on tabular datasets.
In this thesis we explore ways of doing so.
By reviewing the most recent literature on the topic and doing empirical studies, we aim to compose a guideline and highlight the best practices for working with DL and tabular data.

## Challenges for Deep Learning on Tabular Data

This thesis acts as a tutorial for applying Deep Learning to tabular data.
We review the recent literature on DL in general and then zooming in on applying DL to tabular data.
We have identified the major challenges of using DL approaches on tabular data and will review the literature in this context.
These challenges are summarised below, posed as questions:

- **How should input features be represented numerically?**: We have mentioned that tabular data consists of mixed feature types, a combination of categorical and continuous features. The question here relates to how these features should be processed and presented to the model during training.
- **How can we exploit feature interactions?**: Once we have found the optimal feature representation for all feature types, we will need a way to effectively learn the interactions between them and how they relate to the target. This a crucial part for effective ML models on tabular data.
- **How can we be more sample efficient?**:  Tabular datasets are typically not as large as datasets in CV and NLP, and furthermore there is no general large dataset with universal properties that a model can learn from and transfer its knowledge. Thus, a key challenge is being able to learn from less data.
- **How do we interpret the model decisions?**: The use of DL is often restricted by its perceived lack of interpretability. Therefore we need ways of explaining the model output in order for it to be useful in many applications.

Clearly, there are plenty of considerations when it comes to using DL with tabular data. 
The aim of this thesis is to find the best ways of overcoming these challenges, by giving a detailed review of the relevant literature and backing up the claims with empirical results.
The work will help the reader understand the *status quo* of the field and what is required for DL to be as effective as in other data domains such as CV and NLP.

A large part of this work consists of comparing different techniques and algorithms on datasets that are relevant to us.
Furthermore, we suggest ways of improving these techniques, which also needs comparision.
Since theory and practice does not always go hand-in-hand, it is usually advantageous to complement a theoretical study with empirical results. 
In addition, we regard the ability to implement an approach equally as important as understanding the theory behind it. 
We characterise a good empirical experiment as one that is *rigorous* and *reproducible*. 

Recently the field of DL has been criticised for the growing gap between the understanding of its techniques and its practical successes[^talk] where most of the recent focus was on the latter. 
The speakers urged the deep learning community to be more rigorous in their experiments where, for them, the most important part of rigor is better empiricism, not more mathematical theories. 
Better empiricism in classification may include, for example, practices such as using cross-validation to estimate the generalisation ability of a model and reporting standard errors. 
Empirical studies should be more than just trying to beat the benchmark and should also consist of simple experiments that aid in the understanding of how the techniques work. 

[^talk]: Talk given at NIPS2017 - https://www.youtube.com/watch?v=Qi1Yry33TQE

In addition, we want all our experiments to be as reproducible as possible, *i.e.* provide all the code, data and necessary documentation to reproduce the experiments that were done in this thesis[^git]. 
This is often an overlooked feature of experiments, but is however crucial for transparent and accountable reporting and making your work useful for others to build on.

[^git]: All of these are shared publicly at https://github.com/jandremarais/tabularLearner

A more detailed summary of the thesis is outlined shortly.
First we cover the fundamental concepts of Statistical Learning Theory.
These concepts are referred to throughout the thesis and therefore it will be beneficial to be familiar with them.

## Overview of Statistical Learning Theory \label{sec:SLT}

Machine or statistical learning algorithms (used interchangably) are used to perform certain task that are too difficult or inefficient to solve with fixed rule-based programs. 
These algorithms are able to learn how to perform a task from data. 
For an algorithm to learn from data means that it can improve its ability in performing an assigned *task*, with respect to some *performance measure*, by processing *data*.
This section gives a brief look at some of the important types of tasks, data and performance measures in the field of statistical learning.

A learning task describes the way an algorithm should process an observation. 
An observation is a collection of features that have been measured from some object or event that we want the system to process, for example an image.
We will represent an observation by a vector $\boldsymbol{x}\in\mathbb{R}^{p}$ where each element $x_{j}$ of the vector is an observed value of the $j$-th feature, $j=1,\dots,p$. 
For example, the features of an image are usually the color intensity values of the pixels in the image.

Many kinds of tasks can be solved with statistical learning. 
One of the most common learning tasks is that of *classification*, where it is expected of an algorithm to determine which of $K$ categories an input belongs to. 
To solve the classification task, the learning algorithm is usually asked to produce a function $f:\mathbb{R}^{p}\to \{1,\dots,K\}$.
When $y=f(\boldsymbol{x})$, the model assigns an input described by the vector $\boldsymbol{x}$ to a category identified by the numeric code $y$, called the *output* or *response*. 
In other variants of the classification task, $f$ may output a probability distribution over the possible classes.

*Regression* is the other main learning task and requires the algorithm to predict a continuous value given some input. 
This task requires a function $f:\mathbb{R}^{p}\to\mathbb{R}$, where the only difference to classification is the format of its output.

Learning algorithms can learn to perform such tasks by observing a relevant set of data points, *i.e.* a dataset.
A dataset containing $N$ observations of $p$ features is commonly described as a design matrix $X:N\times p$, where each row of the matrix represents a different observation and each column corresponds to a different feature of the observations, *i.e.*

$$
X = 
\begin{bmatrix}
x_{11} & x_{12} & \dots & x_{1p}\\
x_{21} & x_{22} & \dots & x_{2p}\\
\vdots & \vdots & \ddots & \vdots\\
x_{N1} & x_{N2} & \dots & x_{Np}
\end{bmatrix}.
$$
Often the dataset includes annotations for each observation in the form of a label (classification) or a target value (regression). 
The $N$ annotations are represented by the vector $\boldsymbol{y}$, where element $y_{i}$ is associated with the $i$-th row of $X$.
Therefore the response vector may be denoted by

$$
\boldsymbol{y}=
\begin{bmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{N}
\end{bmatrix}.
$$
Note that in the case of multiple labels or targets, a matrix representation $Y:N\times K$ is required.

Statistical learning algorithms can be divided into two main categories, *supervised* and *unsupervised* algorithms, determined by the presence (or absence) of annotations in the dataset to be analysed. 
Unsupervised learning algorithms learn from data consisting only of features, $X$, and are used to find useful properties and structure in the dataset [see @Hastie2009, Ch. 14]. 
On the other hand, superivised learning algorithms learn from datasets which consist of both features and annotations, $(X,Y)$, with the aim to model the relationship between them.
Therefore, both classification and regression are considered to be supervised learning tasks.

In order to evaluate the ability of a learning algorithm to perform its assigned task, we have to design a quantitative performance measure. 
For example, in a classification task we are usually interested in the accuracy of the algorithm, *i.e.* the percentage of times that the algorithm makes the correct classification. 
We are mostly interested in how well the learning algorithm performs on data that it has not seen before, since this demonstrates how well it will perform in real-world situations. Thus we evaluate the algorithm on a *test set* of data points, independent of the *training set* of data points used during the learning process.

For a more concrete example of supervised learning, and keeping in mind that the linear model is one of the main building blocks of neural networks, consider the learning task underlying *linear regression*. 
The objective here is to construct a system which takes a vector $\boldsymbol{x}\in \mathbb{R}^{p}$ as input and predicts the value of a scalar $y\in \mathbb{R}$ in response. 
In the case of linear regression, we assume the output be a linear function of the input. 
Let $\hat{y}$ be the predicted response. We define the output to be 

$$
\hat{y}=\hat{\boldsymbol{w}}^{T}\boldsymbol{x},
$$
where $\hat{\boldsymbol{w}}=[w_{0},w_{1},\dots,w_{p}]$ is a vector of parameters and $\boldsymbol{x}=[1,x_{1},x_{2},\dots,x_{p}]$. 
Note that an intercept is included in the model (also known as a *bias* in machine learning). 
The parameters are values that control the behaviour of the system. We can think of them as a set of *weights* that determine how each feature affects the prediction. 
Hence the learning task can be defined as predicting $y$ from $\boldsymbol{x}$ through $\hat{y}=\hat{\boldsymbol{w}}^{T}\boldsymbol{x}$.

We of course need to define a performance measure to evaluate the linear predictions. 
For a set of observations, an evaluation metric tells us how (dis)similar the predicted output is to the actual response values. 
A very common measure of performance in regression is the *mean squared error* (MSE), given by

$$
MSE = \frac{1}{N}\sum_{i=1}^{N}(y_{i}-\hat{y}_{i})^{2}.
$$
The process of learning from the data (or fitting a model to the data) can be reduced to the following optimisation problem: find the set of weights, $\hat{\boldsymbol{w}}$, which produces a $\hat{\boldsymbol{y}}$ that minimises the MSE. 
Of course this problem has a closed form solution and can quite trivially be found by means of *ordinary least squares* (OLS) [see @Hastie2009, p. 12]. 
However, we have mentioned that we are more interested in the algorithm's performance evaluated on a test set. 
Unfortunately the least squares solution does not guarantee the solution to be optimal in terms of the MSE on a test set, rendering statistical learning to be much more than a pure optimisation problem.

The ability of a model to perform well on previously unobserved inputs is referred to as its *generalisation* ability. 
We also say if a model does not generalise well that the model is overfitting to the training data.
Generalisation is the key challenge of statistical learning. 
One way of improving the generalisation ability of a linear regression model is to modify the optimisation criterion $J$, to include a *weight decay* (or *regularisation*) term. 
That is, we want to minimise
$$
J(\boldsymbol{w})=MSE_{\text{train}} +\lambda\boldsymbol{w}^{T}\boldsymbol{w},
$$
where $J(\boldsymbol{w})$ now expresses preference for smaller weights. 
The parameter $\lambda$ is non-negative and needs to be specified ahead of time. 
It controls the strength of the preference by determining how much influence the penalty term, $\boldsymbol{w}^{T}\boldsymbol{w}$, has on the optimisation criterion. 
If $\lambda=0$, no preference is imposed, and the solution is equivalent to the OLS solution. Larger values of $\lambda$ force the weights to decrease, and thus referred to as a so-called *shrinkage* method ([*cf*. for example @Hastie2009, pp. 61-79] and [@Goodfellow2016]. 

We can further generalise linear regression to the classification scenario. 
First, note the different types of classification schemes. 
Consider $\mathcal{G}$, the discrete set of values which may be assumed by $G$, where $G$ is used to denote a categorical output variable (instead of $Y$). 
Let $|\mathcal{G}|=K$ denote the number of discrete categories in the set $\mathcal{G}$. 
The simplest form of classification is known as binary classification and refers to scenarios where the input is associated with only one of two possible classes, *i.e.* $K=2$. 
When $K>2$, the task is known as multiclass classification. 
In multi-label classification an input may be associated with multiple classes (out of $K$ available classes), where the number of classes that each observation belongs to, is unknown.
Here we start by introducing the two single label classification setups, *viz*. binary and multiclass classification.

In multiclass classification, given the input values $\boldsymbol{X}$, we would like to accurately predict the output, $G$, which we denote by $\hat{G}$.
One approach would be to represent $G$ by an indicator vector $\boldsymbol{Y}_{G}:K\times1$, with elements all zero except in the $G$-th position, where it is assigned a 1, *i.e.* $Y_{k}=1$ for $k=G$ and $Y_{k}=0$ for $k\neq G$, $k=1,2,...,K$. 
We may then treat each of the elements in $\boldsymbol{Y}_{G}$ as quantitative outputs, and predict values for them, denoted by $\hat{\boldsymbol{Y}}=[\hat{Y}_{1},\dots,\hat{Y}_{K}]$. 
The class with the highest predicted value will then be the final categorical prediction of the classifer, *i.e.* $\hat{G}=\arg\max_{k\in\{1,\dots,K\}}\hat{Y}_{k}$.

Within the above framework we therefore seek a function of the inputs which is able to produce accurate predictions of the class scores, *i.e.*
$$
\hat{Y}_{k}=\hat{f}_{k}(\boldsymbol{X}),
$$
for $k=1,\dots, K$. Here $\hat{f}_{k}$ is an estimate of the true function, $f_{k}$, which is meant to capture the relationship between the inputs and output of class $k$. 
As with the linear regression case described above, we can use a linear model $\hat{f}_{k}(\boldsymbol{X})=\hat{\boldsymbol{w}}_{k}^{T}\boldsymbol{X}$ to approximate the true function. 
The linear model for classification divides the input space into a collection of regions labelled according to the classification, where the division is done by linear *decision boundaries* (see \autoref{fig:lin_bound} for an illustration). 
The decision boundary between classes $k$ and $l$ is the set of points for which $\hat{f}_{k}(\boldsymbol{x})=\hat{f}_{l}(\boldsymbol{x})$. 
These set of points form an affine set or hyperplane in the input space.

![Linear model on simple binary classification dataset.\label{fig:lin_bound}](figures/linear_boundary.pdf)

After the weights are estimated from the data, an observation represented by $\boldsymbol{x}$ (including the unit element) can be classified as follows:

- Compute $\hat{f}_{k}(\boldsymbol{x})=\hat{\boldsymbol{w}}_{k}^{T}\boldsymbol{x}$ for all $k=1,\dots,K$.
- Identify the largest component and classify to the corresponding class, *i.e.* $\hat{G}=\arg\max_{k\in\{1,\dots,K\}}\hat{f}_{k}(\boldsymbol{x})$.

One may view the predicted class scores as estimates of the conditional class probabilities (or posterior probabilities), *i.e.* $P(G=k|\boldsymbol{X}=\boldsymbol{x})\approx \hat{f}_{k}(\boldsymbol{x})$. 
However, these values are not the best estimates of posterior probabilities. 
Although the values sum to 1, they do not lie within [0,1]. 
A way to overcome this problem is to estimate the posterior probabilities
using the *logit transform* of $\hat{f}_{k}(\boldsymbol{x})$. 
That is,
$$
P(G=k|\boldsymbol{X}=\boldsymbol{x})\approx\frac{e^{\hat{f}_{k}(\boldsymbol{x})}}{\sum_{l=1}e^{\hat{f}_{l}(\boldsymbol{x})}}.
$$
Through this transformation, the estimates of the posterior probabilities both sum to 1 and are squeezed into [0,1]. 
The above model is the well-known *logistic regression* model [@Hastie2009, p. 119]. 
With this formulation there is no closed form solution for the weights. 
Instead, the weight estimates may be searched for by maximising the log-likelihood function. 
One way of doing this is by minimising the negative log-likelihood using gradient descent, which will be discussed in the next chapter.

Finally in this section, note that any supervised learning problem can also be viewed as a function approximation problem. 
Suppose we are trying to predict a variable $Y$ given an input vector $\boldsymbol{X}$, where we assume the true relationship between them to be given by
$$
Y=f(\boldsymbol{X})+\epsilon,
$$
where $\epsilon$ represents the part of $Y$ that is not predictable from $\boldsymbol{X}$, because of, for example, incomplete features or noise present in the labels. 
Then in function approximation we are estimating $f$ with an estimate $\hat{f}$. 
In parametric function approximation, for example in linear regression, estimation of $f(\boldsymbol{X},\theta)$ is equivalent to estimating the optimal set of weights, $\hat{\theta}$. 
In the remainder of the thesis, we refer to $\hat{f}$ as the *model*, *classifier* or *learner*.

## Outline

This chapter provided the context, motivations, objectives and theoretical backround for this thesis
The outline for the rest of the thesis is given next.

In \Cref{chp:nn} we cover the basics of NNs.
The building blocks of NNs are discussed, introducing neurons, basic layers and how NNs are trained, including basic regularisation techniques.
We attempt to gain insight into what happens inside a NN from the perspective of representation and manifold learning.

\Cref{chp:dl} continues the discussion by focussing on the key advancements in NNs in recent times.
Improved ways of fighting overfitting like data augmentation, dropout and transfer learning are analysed here, as well as the SotA training policy called *1Cycle*.
New developments in architecture design are highlighted and then the chapter concludes with approaches to interpretting NNs and their predictions.
All of the concepts introduced in this chapter can potentially help us build better deep NNs on tabular data.

\Cref{chp:td} is the main chapter of this thesis.
It mainly serves as a literature review of all the work done on DL for tabular data.
It is organised by the modelling challenges faced when working with DL and tabular data, investigating and comparing what other researchers have done to solve the problems.
The core of the content is about finding the right representation for tabular data, through embeddings, and designing architectures that can efficiently learn feature interactions, like with attention models, possibly with the help of unsupervised pretraining.

In \Cref{chp:exp} we empirically evaluate the claims made in the literature.
It acts as an ablation study to evaluate and compare various approaches to tackling the various challenges.
Thus the main experiments are evaluating NNs at various samples sizes, the gains from doing unsupervised pretraining and using data augmentation, and comparing attention modules with classic fully-connected layers.
The chapter also includes a section showing an example of how the resulting NNs can be interpreted using permutation importance and knowledge distillation.

The thesis concludes with \Cref{chp:conc} which summarises the work that was done, and highlights the main take-home points.
Here we validate the if the objectives of the thesis has been achieved.
The limitations of this study are discussed and promising futre research directions are identified.


